{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 딥러닝 시즌2 - TensorFlow\n",
    "\n",
    "## LAB04 - Multi variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|  39753.6680\n",
      "   50|    452.4935\n",
      "  100|     16.3765\n",
      "  150|     11.5083\n",
      "  200|     11.4253\n",
      "  250|     11.3953\n",
      "  300|     11.3661\n",
      "  350|     11.3369\n",
      "  400|     11.3079\n",
      "  450|     11.2790\n",
      "  500|     11.2500\n",
      "  550|     11.2212\n",
      "  600|     11.1924\n",
      "  650|     11.1638\n",
      "  700|     11.1352\n",
      "  750|     11.1067\n",
      "  800|     11.0782\n",
      "  850|     11.0498\n",
      "  900|     11.0216\n",
      "  950|     10.9934\n",
      " 1000|     10.9653\n"
     ]
    }
   ],
   "source": [
    "#data and label\n",
    "x1 =[73.,93.,89.,96.,73.]\n",
    "x2 =[80.,88.,91.,98.,66.]\n",
    "x3 =[75.,93.,90.,100.,70.]\n",
    "Y =[152.,185.,180.,196.,142.]\n",
    "\n",
    "#random weights 초기값은 전부 1로 주었음. 변수가 3개이기에 가중치도 3개!\n",
    "w1 =tf.Variable(tf.random.normal([1]))\n",
    "w2 =tf.Variable(tf.random.normal([1]))\n",
    "w3 =tf.Variable(tf.random.normal([1]))\n",
    "b =tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    #tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1 * x1 + w2 * x2 + w3 * x3 +b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y)) #오차 제곱의 평균값\n",
    "    \n",
    "    #calculates the gradients of the cost\n",
    "    #cost 함수에 대한 [w1,w2,w3,b]의 변수들에 대한 기울기 값을 w1_grad ... 에 할당함.\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1,w2,w3,b])\n",
    "    \n",
    "    #update w1, w2, w3 and b\n",
    "    #각각의 값(w1,w2,w3,b)에 () 안 값 할당\n",
    "    w1.assign_sub(learning_rate*w1_grad)\n",
    "    w2.assign_sub(learning_rate*w2_grad)\n",
    "    w3.assign_sub(learning_rate*w3_grad)\n",
    "    b.assign_sub(learning_rate*b_grad)\n",
    "    \n",
    "    if i%50 ==0:\n",
    "        print(\"{:5}|{:12.4f}\".format(i,cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설함수를 매트릭스를 사용해 표현하면!\n",
    "\n",
    "import numpy 를 해줘야 한다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [73.,80.,75.,152.],\n",
    "    [93.,88.,93.,185.],\n",
    "    [89.,91.,90.,180.],\n",
    "    [96.,98.,100.,196.],\n",
    "    [73.,66.,70.,142.],\n",
    "], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |106701.1016\n",
      "  100 |   20.9929\n",
      "  200 |    7.8332\n",
      "  300 |    7.8068\n",
      "  400 |    7.7821\n",
      "  500 |    7.7576\n",
      "  600 |    7.7332\n",
      "  700 |    7.7089\n",
      "  800 |    7.6847\n",
      "  900 |    7.6607\n",
      " 1000 |    7.6368\n",
      " 1100 |    7.6130\n",
      " 1200 |    7.5893\n",
      " 1300 |    7.5657\n",
      " 1400 |    7.5422\n",
      " 1500 |    7.5189\n",
      " 1600 |    7.4957\n",
      " 1700 |    7.4726\n",
      " 1800 |    7.4496\n",
      " 1900 |    7.4268\n",
      " 2000 |    7.4040\n"
     ]
    }
   ],
   "source": [
    "x=data[:,:-1]#행은 전체, 열은 마지막 열을 제외한 열\n",
    "y=data[:,[-1]]#행은 전체, 열은 마지막 열 만\n",
    "\n",
    "# H=XW 이고, X가 [5,3]이기에 W의 행은 3이 되어야하고 개별 인스턴스 마다 출력이 1개로 일어나므로 열의 값은 1이다.\n",
    "W=tf.Variable(tf.random.normal([3,1]))\n",
    "b=tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "#hypothesis. prediction function\n",
    "def predict(x):\n",
    "    return tf.matmul(x,W)+b #bias 생략할 수도 있음.\n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1):\n",
    "    #record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean(tf.square(predict(x)-y))\n",
    "        \n",
    "    #calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost,[W,b])\n",
    "    \n",
    "    #updates parameters (W and b)\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i %100==0:\n",
    "        print(\"{:5} |{:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights update weights 등을 변수의 갯수만큼 써줘야했는데 매트릭스를 이용하면 한 줄로 끝난다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
